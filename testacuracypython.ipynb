{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aVkaVtdqwJoE",
        "outputId": "041fd909-7f10-40b7-d840-471c88edbf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workout Recommendation System\n",
            "=============================\n",
            "Using dataset: dataset1.csv\n",
            "Using TensorFlow version: 2.18.0\n",
            "Loading and preprocessing data...\n",
            "\n",
            "Missing values count:\n",
            "Umur                0\n",
            "BMI_status          0\n",
            "tinggi_badan        0\n",
            "berat_badan         0\n",
            "Workout1            0\n",
            "Workout2            0\n",
            "Workout3            0\n",
            "Workout4          310\n",
            "Workout5          611\n",
            "banyak_workout      0\n",
            "dtype: int64\n",
            "\n",
            "BMI status distribution:\n",
            "BMI_status\n",
            "normal         301\n",
            "underweight    266\n",
            "obesitas       241\n",
            "overweight     126\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Age category distribution:\n",
            "Kategori_Usia\n",
            "Tua       453\n",
            "Dewasa    283\n",
            "Muda      198\n",
            "Name: count, dtype: int64\n",
            "\n",
            "BMI Status Mapping:\n",
            "normal: 0\n",
            "obesitas: 1\n",
            "overweight: 2\n",
            "underweight: 3\n",
            "\n",
            "Age Category Mapping:\n",
            "Dewasa: 0\n",
            "Muda: 1\n",
            "Tua: 2\n",
            "\n",
            "Total unique workout types: 12\n",
            "Workout types: ['assisted pull up', 'assisted push up', 'berenang', 'bersepeda', 'bersepeda santai', 'dips', 'jogging', 'jogging santai', 'jump squat', 'pull up', 'push up', 'squat']\n",
            "\n",
            "Feature matrix shape: (934, 6)\n",
            "Target matrix shape: (934, 12)\n",
            "\n",
            "Sample counts for each workout type:\n",
            "assisted pull up: 392\n",
            "assisted push up: 507\n",
            "jump squat: 41\n",
            "jogging santai: 85\n",
            "pull up: 301\n",
            "berenang: 418\n",
            "jogging: 566\n",
            "squat: 442\n",
            "bersepeda: 441\n",
            "push up: 426\n",
            "bersepeda santai: 85\n",
            "dips: 45\n",
            "\n",
            "Building and training the model...\n",
            "\n",
            "Model Architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m396\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,628\u001b[0m (45.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,628</span> (45.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,628\u001b[0m (45.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,628</span> (45.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - binary_accuracy: 0.4777 - f1_score: 0.5560 - hamming_loss: 0.3606 - loss: 0.6093 - val_binary_accuracy: 0.7215 - val_f1_score: 0.6643 - val_hamming_loss: 0.2180 - val_loss: 0.4497 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7283 - f1_score: 0.6471 - hamming_loss: 0.2280 - loss: 0.4509 - val_binary_accuracy: 0.7914 - val_f1_score: 0.7246 - val_hamming_loss: 0.1827 - val_loss: 0.3628 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.7908 - f1_score: 0.7337 - hamming_loss: 0.1763 - loss: 0.3685 - val_binary_accuracy: 0.8182 - val_f1_score: 0.7394 - val_hamming_loss: 0.1722 - val_loss: 0.3115 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8135 - f1_score: 0.7478 - hamming_loss: 0.1652 - loss: 0.3282 - val_binary_accuracy: 0.8293 - val_f1_score: 0.7622 - val_hamming_loss: 0.1567 - val_loss: 0.2796 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8381 - f1_score: 0.7576 - hamming_loss: 0.1586 - loss: 0.2892 - val_binary_accuracy: 0.8275 - val_f1_score: 0.7803 - val_hamming_loss: 0.1447 - val_loss: 0.2612 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8392 - f1_score: 0.7747 - hamming_loss: 0.1492 - loss: 0.2773 - val_binary_accuracy: 0.8356 - val_f1_score: 0.7972 - val_hamming_loss: 0.1301 - val_loss: 0.2476 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 0.8445 - f1_score: 0.7757 - hamming_loss: 0.1444 - loss: 0.2645 - val_binary_accuracy: 0.8436 - val_f1_score: 0.8340 - val_hamming_loss: 0.1076 - val_loss: 0.2362 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8438 - f1_score: 0.7923 - hamming_loss: 0.1333 - loss: 0.2635 - val_binary_accuracy: 0.8529 - val_f1_score: 0.8580 - val_hamming_loss: 0.0952 - val_loss: 0.2174 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8589 - f1_score: 0.8197 - hamming_loss: 0.1191 - loss: 0.2429 - val_binary_accuracy: 0.8775 - val_f1_score: 0.8523 - val_hamming_loss: 0.1007 - val_loss: 0.2084 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8660 - f1_score: 0.8266 - hamming_loss: 0.1150 - loss: 0.2300 - val_binary_accuracy: 0.8779 - val_f1_score: 0.8569 - val_hamming_loss: 0.0933 - val_loss: 0.1961 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8790 - f1_score: 0.8279 - hamming_loss: 0.1144 - loss: 0.2288 - val_binary_accuracy: 0.8779 - val_f1_score: 0.8520 - val_hamming_loss: 0.1003 - val_loss: 0.1975 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8774 - f1_score: 0.8349 - hamming_loss: 0.1085 - loss: 0.2159 - val_binary_accuracy: 0.8779 - val_f1_score: 0.8574 - val_hamming_loss: 0.0952 - val_loss: 0.1895 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - binary_accuracy: 0.8796 - f1_score: 0.8273 - hamming_loss: 0.1146 - loss: 0.2182 - val_binary_accuracy: 0.8779 - val_f1_score: 0.8530 - val_hamming_loss: 0.0977 - val_loss: 0.1913 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.8813 - f1_score: 0.8386 - hamming_loss: 0.1051 - loss: 0.2086 - val_binary_accuracy: 0.8779 - val_f1_score: 0.8585 - val_hamming_loss: 0.0922 - val_loss: 0.1861 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - binary_accuracy: 0.8738 - f1_score: 0.8333 - hamming_loss: 0.1092 - loss: 0.2132 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8513 - val_hamming_loss: 0.0978 - val_loss: 0.1857 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - binary_accuracy: 0.8798 - f1_score: 0.8340 - hamming_loss: 0.1100 - loss: 0.2074 - val_binary_accuracy: 0.8806 - val_f1_score: 0.8618 - val_hamming_loss: 0.0891 - val_loss: 0.1809 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 0.8813 - f1_score: 0.8400 - hamming_loss: 0.1040 - loss: 0.2056 - val_binary_accuracy: 0.8824 - val_f1_score: 0.8582 - val_hamming_loss: 0.0913 - val_loss: 0.1803 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8802 - f1_score: 0.8493 - hamming_loss: 0.0994 - loss: 0.1960 - val_binary_accuracy: 0.8815 - val_f1_score: 0.8626 - val_hamming_loss: 0.0874 - val_loss: 0.1786 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8786 - f1_score: 0.8421 - hamming_loss: 0.1024 - loss: 0.2003 - val_binary_accuracy: 0.8855 - val_f1_score: 0.8636 - val_hamming_loss: 0.0865 - val_loss: 0.1777 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8788 - f1_score: 0.8298 - hamming_loss: 0.1091 - loss: 0.2035 - val_binary_accuracy: 0.8841 - val_f1_score: 0.8620 - val_hamming_loss: 0.0871 - val_loss: 0.1771 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8768 - f1_score: 0.8440 - hamming_loss: 0.1007 - loss: 0.1980 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8616 - val_hamming_loss: 0.0887 - val_loss: 0.1751 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8869 - f1_score: 0.8528 - hamming_loss: 0.0990 - loss: 0.1915 - val_binary_accuracy: 0.8877 - val_f1_score: 0.8606 - val_hamming_loss: 0.0878 - val_loss: 0.1756 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8839 - f1_score: 0.8490 - hamming_loss: 0.0993 - loss: 0.1945 - val_binary_accuracy: 0.8810 - val_f1_score: 0.8614 - val_hamming_loss: 0.0875 - val_loss: 0.1739 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8798 - f1_score: 0.8487 - hamming_loss: 0.0989 - loss: 0.1926 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8618 - val_hamming_loss: 0.0878 - val_loss: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8806 - f1_score: 0.8450 - hamming_loss: 0.1029 - loss: 0.1961 - val_binary_accuracy: 0.8819 - val_f1_score: 0.8603 - val_hamming_loss: 0.0874 - val_loss: 0.1740 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8811 - f1_score: 0.8451 - hamming_loss: 0.1000 - loss: 0.1913 - val_binary_accuracy: 0.8824 - val_f1_score: 0.8633 - val_hamming_loss: 0.0874 - val_loss: 0.1731 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8831 - f1_score: 0.8436 - hamming_loss: 0.1015 - loss: 0.1914 - val_binary_accuracy: 0.8824 - val_f1_score: 0.8633 - val_hamming_loss: 0.0870 - val_loss: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8792 - f1_score: 0.8568 - hamming_loss: 0.0937 - loss: 0.1898 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8614 - val_hamming_loss: 0.0887 - val_loss: 0.1719 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8854 - f1_score: 0.8495 - hamming_loss: 0.0983 - loss: 0.1857 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8616 - val_hamming_loss: 0.0875 - val_loss: 0.1701 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8911 - f1_score: 0.8583 - hamming_loss: 0.0929 - loss: 0.1847 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8600 - val_hamming_loss: 0.0875 - val_loss: 0.1723 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8879 - f1_score: 0.8523 - hamming_loss: 0.0955 - loss: 0.1872 - val_binary_accuracy: 0.8824 - val_f1_score: 0.8621 - val_hamming_loss: 0.0878 - val_loss: 0.1698 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8865 - f1_score: 0.8556 - hamming_loss: 0.0947 - loss: 0.1867 - val_binary_accuracy: 0.8837 - val_f1_score: 0.8622 - val_hamming_loss: 0.0887 - val_loss: 0.1700 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8886 - f1_score: 0.8580 - hamming_loss: 0.0939 - loss: 0.1809 - val_binary_accuracy: 0.8824 - val_f1_score: 0.8604 - val_hamming_loss: 0.0893 - val_loss: 0.1688 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.8835 - f1_score: 0.8494 - hamming_loss: 0.0977 - loss: 0.1935 - val_binary_accuracy: 0.8841 - val_f1_score: 0.8608 - val_hamming_loss: 0.0884 - val_loss: 0.1705 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8823 - f1_score: 0.8526 - hamming_loss: 0.0962 - loss: 0.1872 - val_binary_accuracy: 0.8850 - val_f1_score: 0.8609 - val_hamming_loss: 0.0880 - val_loss: 0.1692 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.8909 - f1_score: 0.8552 - hamming_loss: 0.0928 - loss: 0.1794 - val_binary_accuracy: 0.8810 - val_f1_score: 0.8637 - val_hamming_loss: 0.0875 - val_loss: 0.1693 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - binary_accuracy: 0.8864 - f1_score: 0.8495 - hamming_loss: 0.0977 - loss: 0.1845 - val_binary_accuracy: 0.8841 - val_f1_score: 0.8626 - val_hamming_loss: 0.0874 - val_loss: 0.1679 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - binary_accuracy: 0.8853 - f1_score: 0.8536 - hamming_loss: 0.0956 - loss: 0.1898 - val_binary_accuracy: 0.8855 - val_f1_score: 0.8627 - val_hamming_loss: 0.0870 - val_loss: 0.1678 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8839 - f1_score: 0.8503 - hamming_loss: 0.0963 - loss: 0.1853 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8619 - val_hamming_loss: 0.0874 - val_loss: 0.1679 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8818 - f1_score: 0.8401 - hamming_loss: 0.1031 - loss: 0.1877 - val_binary_accuracy: 0.8832 - val_f1_score: 0.8637 - val_hamming_loss: 0.0862 - val_loss: 0.1674 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8819 - f1_score: 0.8503 - hamming_loss: 0.0963 - loss: 0.1868 - val_binary_accuracy: 0.8837 - val_f1_score: 0.8643 - val_hamming_loss: 0.0871 - val_loss: 0.1666 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8783 - f1_score: 0.8494 - hamming_loss: 0.0975 - loss: 0.1894 - val_binary_accuracy: 0.8828 - val_f1_score: 0.8622 - val_hamming_loss: 0.0874 - val_loss: 0.1665 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8791 - f1_score: 0.8382 - hamming_loss: 0.1037 - loss: 0.1879 - val_binary_accuracy: 0.8855 - val_f1_score: 0.8619 - val_hamming_loss: 0.0878 - val_loss: 0.1667 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8893 - f1_score: 0.8504 - hamming_loss: 0.0970 - loss: 0.1821 - val_binary_accuracy: 0.8855 - val_f1_score: 0.8619 - val_hamming_loss: 0.0893 - val_loss: 0.1664 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8941 - f1_score: 0.8651 - hamming_loss: 0.0887 - loss: 0.1705 - val_binary_accuracy: 0.8841 - val_f1_score: 0.8632 - val_hamming_loss: 0.0871 - val_loss: 0.1659 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8822 - f1_score: 0.8467 - hamming_loss: 0.0989 - loss: 0.1838 - val_binary_accuracy: 0.8850 - val_f1_score: 0.8608 - val_hamming_loss: 0.0904 - val_loss: 0.1652 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.8867 - f1_score: 0.8586 - hamming_loss: 0.0926 - loss: 0.1751 - val_binary_accuracy: 0.8832 - val_f1_score: 0.8623 - val_hamming_loss: 0.0891 - val_loss: 0.1649 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8833 - f1_score: 0.8554 - hamming_loss: 0.0946 - loss: 0.1776 - val_binary_accuracy: 0.8846 - val_f1_score: 0.8596 - val_hamming_loss: 0.0901 - val_loss: 0.1649 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8824 - f1_score: 0.8486 - hamming_loss: 0.0981 - loss: 0.1814 - val_binary_accuracy: 0.8841 - val_f1_score: 0.8578 - val_hamming_loss: 0.0906 - val_loss: 0.1650 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8841 - f1_score: 0.8524 - hamming_loss: 0.0947 - loss: 0.1807 - val_binary_accuracy: 0.8832 - val_f1_score: 0.8600 - val_hamming_loss: 0.0904 - val_loss: 0.1631 - learning_rate: 0.0010\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8772 - f1_score: 0.8550 - hamming_loss: 0.0924 - loss: 0.1694 \n",
            "\n",
            "Test Loss: 0.1631\n",
            "Test Hamming Loss: 0.0911\n",
            "Test F1 Score: 0.8598\n",
            "Test Binary Accuracy: 0.8832\n",
            "\n",
            "Testing the model with sample inputs:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "\n",
            "For person with height 170cm, weight 65kg, age 25:\n",
            "BMI Category: normal, Age Category: Muda\n",
            "Recommended 5 workouts:\n",
            "1. pull up (confidence: 0.9993)\n",
            "2. push up (confidence: 0.9814)\n",
            "3. jogging (confidence: 0.7814)\n",
            "4. bersepeda (confidence: 0.5354)\n",
            "5. berenang (confidence: 0.4987)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "For person with height 160cm, weight 45kg, age 22:\n",
            "BMI Category: underweight, Age Category: Muda\n",
            "Recommended 5 workouts:\n",
            "1. assisted pull up (confidence: 1.0000)\n",
            "2. assisted push up (confidence: 1.0000)\n",
            "3. jogging (confidence: 0.9721)\n",
            "4. bersepeda (confidence: 0.9067)\n",
            "5. berenang (confidence: 0.8604)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "For person with height 175cm, weight 85kg, age 25:\n",
            "BMI Category: overweight, Age Category: Muda\n",
            "Recommended 5 workouts:\n",
            "1. assisted pull up (confidence: 1.0000)\n",
            "2. push up (confidence: 1.0000)\n",
            "3. squat (confidence: 0.9963)\n",
            "4. jogging santai (confidence: 0.9019)\n",
            "5. bersepeda santai (confidence: 0.8958)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "For person with height 170cm, weight 95kg, age 25:\n",
            "BMI Category: obesitas, Age Category: Muda\n",
            "Recommended 5 workouts:\n",
            "1. assisted push up (confidence: 1.0000)\n",
            "2. squat (confidence: 1.0000)\n",
            "3. jogging (confidence: 0.9907)\n",
            "4. berenang (confidence: 0.9747)\n",
            "5. bersepeda (confidence: 0.9713)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "For person with height 170cm, weight 75kg, age 40:\n",
            "BMI Category: overweight, Age Category: Dewasa\n",
            "Recommended 4 workouts:\n",
            "1. push up (confidence: 1.0000)\n",
            "2. assisted pull up (confidence: 0.9999)\n",
            "3. squat (confidence: 0.9978)\n",
            "4. jogging santai (confidence: 0.6857)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "For person with height 160cm, weight 50kg, age 40:\n",
            "BMI Category: normal, Age Category: Dewasa\n",
            "Recommended 4 workouts:\n",
            "1. pull up (confidence: 0.9983)\n",
            "2. push up (confidence: 0.9864)\n",
            "3. jogging (confidence: 0.6875)\n",
            "4. squat (confidence: 0.4564)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "For person with height 175cm, weight 90kg, age 40:\n",
            "BMI Category: overweight, Age Category: Dewasa\n",
            "Recommended 4 workouts:\n",
            "1. push up (confidence: 0.9999)\n",
            "2. assisted pull up (confidence: 0.9997)\n",
            "3. squat (confidence: 0.9977)\n",
            "4. jogging santai (confidence: 0.6618)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "For person with height 170cm, weight 100kg, age 40:\n",
            "BMI Category: obesitas, Age Category: Dewasa\n",
            "Recommended 4 workouts:\n",
            "1. assisted push up (confidence: 1.0000)\n",
            "2. squat (confidence: 1.0000)\n",
            "3. jogging (confidence: 0.8288)\n",
            "4. berenang (confidence: 0.7766)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "For person with height 160cm, weight 45kg, age 65:\n",
            "BMI Category: underweight, Age Category: Tua\n",
            "Recommended 3 workouts:\n",
            "1. assisted pull up (confidence: 1.0000)\n",
            "2. assisted push up (confidence: 1.0000)\n",
            "3. bersepeda (confidence: 0.4046)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "For person with height 165cm, weight 70kg, age 65:\n",
            "BMI Category: overweight, Age Category: Tua\n",
            "Recommended 3 workouts:\n",
            "1. assisted pull up (confidence: 0.9998)\n",
            "2. push up (confidence: 0.9991)\n",
            "3. bersepeda santai (confidence: 0.5797)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\n",
            "For person with height 165cm, weight 85kg, age 65:\n",
            "BMI Category: obesitas, Age Category: Tua\n",
            "Recommended 3 workouts:\n",
            "1. assisted push up (confidence: 1.0000)\n",
            "2. squat (confidence: 1.0000)\n",
            "3. berenang (confidence: 0.4599)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For person with height 160cm, weight 95kg, age 65:\n",
            "BMI Category: obesitas, Age Category: Tua\n",
            "Recommended 3 workouts:\n",
            "1. assisted push up (confidence: 1.0000)\n",
            "2. squat (confidence: 1.0000)\n",
            "3. berenang (confidence: 0.8770)\n",
            "\n",
            "Done! The model has been trained successfully.\n",
            "\n",
            "Final model metrics:\n",
            "- Loss: 0.1631\n",
            "- Hamming Loss: 0.0911\n",
            "- F1 Score: 0.8598\n",
            "- Binary Accuracy: 0.8832\n",
            "\n",
            "Workout Recommendation System\n",
            "-----------------------------\n",
            "Enter your height (cm): 177\n",
            "Enter your weight (kg): 77\n",
            "Enter your age: 17\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Based on your data:\n",
            "- Height: 177.0cm\n",
            "- Weight: 77.0kg\n",
            "- Age: 17\n",
            "- BMI: 24.58 (normal)\n",
            "- Age Category: Muda\n",
            "\n",
            "We recommend the following 5 workouts:\n",
            "1. pull up (confidence: 0.9973)\n",
            "2. jogging (confidence: 0.8638)\n",
            "3. push up (confidence: 0.8387)\n",
            "4. squat (confidence: 0.7676)\n",
            "5. bersepeda (confidence: 0.6210)\n",
            "\n",
            "Want to try another recommendation? (y/n): n\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class WorkoutRecommendationSystem:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.bmi_status_encoder = None\n",
        "        self.age_category_encoder = None\n",
        "        self.workout_encoder = None\n",
        "        self.workout_decoder = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def train(self, dataset_path='dataset1.csv'):\n",
        "        \"\"\"Train the workout recommendation model\"\"\"\n",
        "        print(\"Using TensorFlow version:\", tf.__version__)\n",
        "\n",
        "        # Load dataset\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "        df = pd.read_csv(dataset_path)\n",
        "\n",
        "        # Check for missing values\n",
        "        print(\"\\nMissing values count:\")\n",
        "        print(df.isna().sum())\n",
        "\n",
        "        # Data preprocessing\n",
        "        # Replace NaN values with empty string for workout columns\n",
        "        workout_cols = ['Workout1', 'Workout2', 'Workout3', 'Workout4', 'Workout5']\n",
        "        df[workout_cols] = df[workout_cols].fillna('')\n",
        "\n",
        "        # Create age category based on age ranges\n",
        "        df['Kategori_Usia'] = df['Umur'].apply(self.get_age_category)\n",
        "\n",
        "        # BMI status is already in the dataset as BMI_status\n",
        "\n",
        "        # Check BMI distribution\n",
        "        print(\"\\nBMI status distribution:\")\n",
        "        print(df['BMI_status'].value_counts())\n",
        "        print(\"\\nAge category distribution:\")\n",
        "        print(df['Kategori_Usia'].value_counts())\n",
        "\n",
        "        # Create encoders\n",
        "        self.bmi_status_encoder = LabelEncoder()\n",
        "        self.age_category_encoder = LabelEncoder()\n",
        "\n",
        "        # Fit and transform categorical features\n",
        "        df['BMI_status_Encoded'] = self.bmi_status_encoder.fit_transform(df['BMI_status'])\n",
        "        df['Kategori_Usia_Encoded'] = self.age_category_encoder.fit_transform(df['Kategori_Usia'])\n",
        "\n",
        "        # Print encoder mappings\n",
        "        print(\"\\nBMI Status Mapping:\")\n",
        "        for i, category in enumerate(self.bmi_status_encoder.classes_):\n",
        "            print(f\"{category}: {i}\")\n",
        "\n",
        "        print(\"\\nAge Category Mapping:\")\n",
        "        for i, category in enumerate(self.age_category_encoder.classes_):\n",
        "            print(f\"{category}: {i}\")\n",
        "\n",
        "        # Scale numerical features\n",
        "        self.scaler = MinMaxScaler()\n",
        "        numerical_cols = ['tinggi_badan', 'berat_badan', 'Umur']\n",
        "        # Add BMI calculation for consistency, even though BMI_status exists\n",
        "        df['BMI'] = df['berat_badan'] / ((df['tinggi_badan'] / 100) ** 2)\n",
        "        numerical_cols.append('BMI')\n",
        "        df[numerical_cols] = self.scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "        # Create a mapping of workout types\n",
        "        unique_workouts = set()\n",
        "        for col in workout_cols:\n",
        "            unique_workouts.update(df[col].unique())\n",
        "        unique_workouts.discard('')  # Remove empty string\n",
        "\n",
        "        print(f\"\\nTotal unique workout types: {len(unique_workouts)}\")\n",
        "        print(\"Workout types:\", sorted(unique_workouts))\n",
        "\n",
        "        # Create workout encoder\n",
        "        self.workout_encoder = {workout: i for i, workout in enumerate(unique_workouts)}\n",
        "        self.workout_decoder = {i: workout for workout, i in self.workout_encoder.items()}\n",
        "\n",
        "        # Create feature matrix X and target matrix Y\n",
        "        X_features = df[['tinggi_badan', 'berat_badan', 'Umur', 'BMI',\n",
        "                         'BMI_status_Encoded', 'Kategori_Usia_Encoded']].values\n",
        "\n",
        "        Y = np.array([self._get_workout_encodings(row, workout_cols) for _, row in df.iterrows()])\n",
        "\n",
        "        print(f\"\\nFeature matrix shape: {X_features.shape}\")\n",
        "        print(f\"Target matrix shape: {Y.shape}\")\n",
        "\n",
        "        # Print sample count for each workout type\n",
        "        print(\"\\nSample counts for each workout type:\")\n",
        "        workout_counts = Y.sum(axis=0)\n",
        "        for i, count in enumerate(workout_counts):\n",
        "            if count > 0:  # Only show workouts that appear in the dataset\n",
        "                print(f\"{self.workout_decoder[i]}: {int(count)}\")\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Build and train model\n",
        "        print(\"\\nBuilding and training the model...\")\n",
        "        self.model = self._build_recommendation_model(X_features.shape[1], len(unique_workouts))\n",
        "\n",
        "        # Print model summary\n",
        "        print(\"\\nModel Architecture:\")\n",
        "        self.model.summary()\n",
        "\n",
        "        # Callbacks\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=20,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=10,\n",
        "            min_lr=0.00001\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            X_train, Y_train,\n",
        "            epochs=50,\n",
        "            batch_size=8,\n",
        "            validation_data=(X_test, Y_test),\n",
        "            verbose=1,\n",
        "            callbacks=[early_stopping, reduce_lr]\n",
        "        )\n",
        "\n",
        "        # Evaluate model on test data\n",
        "        test_loss, test_hamming_loss, test_f1, test_accuracy = self.model.evaluate(X_test, Y_test)\n",
        "        print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
        "        print(f\"Test Hamming Loss: {test_hamming_loss:.4f}\")\n",
        "        print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "        print(f\"Test Binary Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        # Test the model with examples\n",
        "        self._test_model_examples()\n",
        "\n",
        "        print(\"\\nDone! The model has been trained successfully.\")\n",
        "\n",
        "        # Return metrics for easier access\n",
        "        return {\n",
        "            'test_loss': test_loss,\n",
        "            'test_hamming_loss': test_hamming_loss,\n",
        "            'test_f1': test_f1,\n",
        "            'test_accuracy': test_accuracy\n",
        "        }\n",
        "\n",
        "    def _get_workout_encodings(self, row, workout_cols):\n",
        "        \"\"\"Convert row's workout data to one-hot encoding\"\"\"\n",
        "        workout_encoding = np.zeros(len(self.workout_encoder))\n",
        "        for col in workout_cols:\n",
        "            if row[col] and row[col] in self.workout_encoder:\n",
        "                workout_encoding[self.workout_encoder[row[col]]] = 1\n",
        "        return workout_encoding\n",
        "\n",
        "    def _build_recommendation_model(self, input_shape, num_workouts):\n",
        "        \"\"\"Build the neural network model\"\"\"\n",
        "        # Input layer\n",
        "        inputs = Input(shape=(input_shape,))\n",
        "\n",
        "        # Hidden layers\n",
        "        x = Dense(128, activation='relu')(inputs)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(64, activation='relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        # Output layer\n",
        "        outputs = Dense(num_workouts, activation='sigmoid')(x)\n",
        "\n",
        "        # Create and compile model\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        # Define custom metrics for multi-label classification\n",
        "        def hamming_loss(y_true, y_pred):\n",
        "            # Convert predictions to binary (0 or 1)\n",
        "            threshold = 0.5\n",
        "            y_pred_binary = tf.cast(tf.greater_equal(y_pred, threshold), tf.float32)\n",
        "\n",
        "            # Calculate Hamming loss\n",
        "            return tf.reduce_mean(tf.cast(tf.not_equal(y_true, y_pred_binary), tf.float32))\n",
        "\n",
        "        def f1_score(y_true, y_pred):\n",
        "            # Convert predictions to binary (0 or 1)\n",
        "            threshold = 0.5\n",
        "            y_pred_binary = tf.cast(tf.greater_equal(y_pred, threshold), tf.float32)\n",
        "\n",
        "            # Calculate true positives, false positives, false negatives\n",
        "            true_positives = tf.reduce_sum(y_true * y_pred_binary)\n",
        "            false_positives = tf.reduce_sum((1 - y_true) * y_pred_binary)\n",
        "            false_negatives = tf.reduce_sum(y_true * (1 - y_pred_binary))\n",
        "\n",
        "            # Calculate precision and recall\n",
        "            precision = true_positives / (true_positives + false_positives + tf.keras.backend.epsilon())\n",
        "            recall = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())\n",
        "\n",
        "            # Calculate F1 score\n",
        "            return 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=[hamming_loss, f1_score, tf.keras.metrics.BinaryAccuracy(threshold=0.3)]\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _test_model_examples(self):\n",
        "        \"\"\"Test the model with sample inputs\"\"\"\n",
        "        print(\"\\nTesting the model with sample inputs:\")\n",
        "\n",
        "\n",
        "                # Muda, Normal\n",
        "        height1, weight1, age1 = 170, 65, 25  # Normal weight for a young adult\n",
        "        recommendations1, num_workouts1, bmi_cat1, age_cat1 = self.recommend(height1, weight1, age1, include_details=True)\n",
        "        print(f\"\\nFor person with height {height1}cm, weight {weight1}kg, age {age1}:\")\n",
        "        print(f\"BMI Category: {bmi_cat1}, Age Category: {age_cat1}\")\n",
        "        print(f\"Recommended {num_workouts1} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations1, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Muda, Underweight\n",
        "        height2, weight2, age2 = 160, 45, 22  # Underweight for a young adult\n",
        "        recommendations2, num_workouts2, bmi_cat2, age_cat2 = self.recommend(height2, weight2, age2, include_details=True)\n",
        "        print(f\"\\nFor person with height {height2}cm, weight {weight2}kg, age {age2}:\")\n",
        "        print(f\"BMI Category: {bmi_cat2}, Age Category: {age_cat2}\")\n",
        "        print(f\"Recommended {num_workouts2} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations2, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Muda, Overweight\n",
        "        height3, weight3, age3 = 175, 85, 25  # Overweight for a young adult\n",
        "        recommendations3, num_workouts3, bmi_cat3, age_cat3 = self.recommend(height3, weight3, age3, include_details=True)\n",
        "        print(f\"\\nFor person with height {height3}cm, weight {weight3}kg, age {age3}:\")\n",
        "        print(f\"BMI Category: {bmi_cat3}, Age Category: {age_cat3}\")\n",
        "        print(f\"Recommended {num_workouts3} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations3, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Muda, Obesitas\n",
        "        height4, weight4, age4 = 170, 95, 25  # Obesity for a young adult\n",
        "        recommendations4, num_workouts4, bmi_cat4, age_cat4 = self.recommend(height4, weight4, age4, include_details=True)\n",
        "        print(f\"\\nFor person with height {height4}cm, weight {weight4}kg, age {age4}:\")\n",
        "        print(f\"BMI Category: {bmi_cat4}, Age Category: {age_cat4}\")\n",
        "        print(f\"Recommended {num_workouts4} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations4, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Dewasa, Normal\n",
        "        height5, weight5, age5 = 170, 75, 40  # Normal weight for an adult\n",
        "        recommendations5, num_workouts5, bmi_cat5, age_cat5 = self.recommend(height5, weight5, age5, include_details=True)\n",
        "        print(f\"\\nFor person with height {height5}cm, weight {weight5}kg, age {age5}:\")\n",
        "        print(f\"BMI Category: {bmi_cat5}, Age Category: {age_cat5}\")\n",
        "        print(f\"Recommended {num_workouts5} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations5, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Dewasa, Underweight\n",
        "        height6, weight6, age6 = 160, 50, 40  # Underweight for an adult\n",
        "        recommendations6, num_workouts6, bmi_cat6, age_cat6 = self.recommend(height6, weight6, age6, include_details=True)\n",
        "        print(f\"\\nFor person with height {height6}cm, weight {weight6}kg, age {age6}:\")\n",
        "        print(f\"BMI Category: {bmi_cat6}, Age Category: {age_cat6}\")\n",
        "        print(f\"Recommended {num_workouts6} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations6, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Dewasa, Overweight\n",
        "        height7, weight7, age7 = 175, 90, 40  # Overweight for an adult\n",
        "        recommendations7, num_workouts7, bmi_cat7, age_cat7 = self.recommend(height7, weight7, age7, include_details=True)\n",
        "        print(f\"\\nFor person with height {height7}cm, weight {weight7}kg, age {age7}:\")\n",
        "        print(f\"BMI Category: {bmi_cat7}, Age Category: {age_cat7}\")\n",
        "        print(f\"Recommended {num_workouts7} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations7, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Dewasa, Obesitas\n",
        "        height8, weight8, age8 = 170, 100, 40  # Obesity for an adult\n",
        "        recommendations8, num_workouts8, bmi_cat8, age_cat8 = self.recommend(height8, weight8, age8, include_details=True)\n",
        "        print(f\"\\nFor person with height {height8}cm, weight {weight8}kg, age {age8}:\")\n",
        "        print(f\"BMI Category: {bmi_cat8}, Age Category: {age_cat8}\")\n",
        "        print(f\"Recommended {num_workouts8} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations8, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Tua, Underweight\n",
        "        height9, weight9, age9 = 160, 45, 65  # Underweight for an older adult\n",
        "        recommendations9, num_workouts9, bmi_cat9, age_cat9 = self.recommend(height9, weight9, age9, include_details=True)\n",
        "        print(f\"\\nFor person with height {height9}cm, weight {weight9}kg, age {age9}:\")\n",
        "        print(f\"BMI Category: {bmi_cat9}, Age Category: {age_cat9}\")\n",
        "        print(f\"Recommended {num_workouts9} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations9, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Tua, Normal\n",
        "        height10, weight10, age10 = 165, 70, 65  # Normal weight for an older adult\n",
        "        recommendations10, num_workouts10, bmi_cat10, age_cat10 = self.recommend(height10, weight10, age10, include_details=True)\n",
        "        print(f\"\\nFor person with height {height10}cm, weight {weight10}kg, age {age10}:\")\n",
        "        print(f\"BMI Category: {bmi_cat10}, Age Category: {age_cat10}\")\n",
        "        print(f\"Recommended {num_workouts10} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations10, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Tua, Overweight\n",
        "        height11, weight11, age11 = 165, 85, 65  # Overweight for an older adult\n",
        "        recommendations11, num_workouts11, bmi_cat11, age_cat11 = self.recommend(height11, weight11, age11, include_details=True)\n",
        "        print(f\"\\nFor person with height {height11}cm, weight {weight11}kg, age {age11}:\")\n",
        "        print(f\"BMI Category: {bmi_cat11}, Age Category: {age_cat11}\")\n",
        "        print(f\"Recommended {num_workouts11} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations11, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "        # Tua, Obesitas\n",
        "        height12, weight12, age12 = 160, 95, 65  # Obesity for an older adult\n",
        "        recommendations12, num_workouts12, bmi_cat12, age_cat12 = self.recommend(height12, weight12, age12, include_details=True)\n",
        "        print(f\"\\nFor person with height {height12}cm, weight {weight12}kg, age {age12}:\")\n",
        "        print(f\"BMI Category: {bmi_cat12}, Age Category: {age_cat12}\")\n",
        "        print(f\"Recommended {num_workouts12} workouts:\")\n",
        "        for i, (workout, score) in enumerate(recommendations12, 1):\n",
        "            print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "\n",
        "\n",
        "    def get_bmi_category(self, bmi):\n",
        "        \"\"\"Determine BMI category from BMI value\"\"\"\n",
        "        if bmi < 18.5:\n",
        "            return 'underweight'\n",
        "        elif bmi < 25:\n",
        "            return 'normal'\n",
        "        elif bmi < 30:\n",
        "            return 'overweight'\n",
        "        else:\n",
        "            return 'obesitas'\n",
        "\n",
        "    def get_age_category(self, age):\n",
        "        \"\"\"Determine age category from age value\"\"\"\n",
        "        if age < 36:\n",
        "            return 'Muda'\n",
        "        elif age < 61:\n",
        "            return 'Dewasa'\n",
        "        else:\n",
        "            return 'Tua'\n",
        "\n",
        "    def recommend(self, height, weight, age, include_details=False):\n",
        "        \"\"\"\n",
        "        Recommend workouts based on height, weight, and age\n",
        "\n",
        "        Parameters:\n",
        "        - height: Height in cm\n",
        "        - weight: Weight in kg\n",
        "        - age: Age in years\n",
        "        - include_details: If True, return scores and categories\n",
        "\n",
        "        Returns:\n",
        "        - If include_details=False: List of recommended workouts, number of recommended workouts\n",
        "        - If include_details=True: List of (workout, score) tuples, number of workouts, BMI category, age category\n",
        "        \"\"\"\n",
        "        # Calculate BMI\n",
        "        height_m = height / 100\n",
        "        bmi = weight / (height_m ** 2)\n",
        "\n",
        "        # Get categories\n",
        "        bmi_category = self.get_bmi_category(bmi)\n",
        "        age_category = self.get_age_category(age)\n",
        "\n",
        "        # Encode categories\n",
        "        try:\n",
        "            bmi_encoded = self.bmi_status_encoder.transform([bmi_category])[0]\n",
        "            age_encoded = self.age_category_encoder.transform([age_category])[0]\n",
        "        except:\n",
        "            print(f\"Warning: Could not encode BMI category '{bmi_category}' or age category '{age_category}'.\")\n",
        "            print(\"Using default encoding values.\")\n",
        "            bmi_encoded = 0\n",
        "            age_encoded = 0\n",
        "\n",
        "        # Scale features\n",
        "        features = np.array([[height, weight, age, bmi]])\n",
        "        scaled_features = self.scaler.transform(features)\n",
        "\n",
        "        # Create input array\n",
        "        input_data = np.array([[\n",
        "            scaled_features[0][0],  # Height\n",
        "            scaled_features[0][1],  # Weight\n",
        "            scaled_features[0][2],  # Age\n",
        "            scaled_features[0][3],  # BMI\n",
        "            bmi_encoded,            # BMI category\n",
        "            age_encoded             # Age category\n",
        "        ]])\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = self.model.predict(input_data)[0]\n",
        "\n",
        "        # Determine number of workouts based on age category\n",
        "        # (following the pattern from the dataset)\n",
        "        if age_category == 'Muda':\n",
        "            num_workouts = 5  # Young gets 5 workouts\n",
        "        elif age_category == 'Dewasa':\n",
        "            num_workouts = 4  # Adults get 4 workouts\n",
        "        else:  # Tua (Elderly)\n",
        "            num_workouts = 3  # Elderly get 3 workouts\n",
        "\n",
        "        # Get top workout indices\n",
        "        top_indices = predictions.argsort()[-num_workouts:][::-1]\n",
        "\n",
        "        if include_details:\n",
        "            # Return workouts with confidence scores and categories\n",
        "            recommendations = [(self.workout_decoder[idx], predictions[idx]) for idx in top_indices]\n",
        "            return recommendations, num_workouts, bmi_category, age_category\n",
        "        else:\n",
        "            # Return only workout names\n",
        "            recommendations = [self.workout_decoder[idx] for idx in top_indices]\n",
        "            return recommendations, num_workouts\n",
        "\n",
        "    def interactive_mode(self):\n",
        "        \"\"\"Run the system in interactive mode for making recommendations\"\"\"\n",
        "        print(\"\\nWorkout Recommendation System\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                try:\n",
        "                    height = float(input(\"Enter your height (cm): \"))\n",
        "                    weight = float(input(\"Enter your weight (kg): \"))\n",
        "                    age = int(input(\"Enter your age: \"))\n",
        "\n",
        "                    # Get recommendations with details\n",
        "                    recommendations, num_workouts, bmi_cat, age_cat = self.recommend(height, weight, age, include_details=True)\n",
        "\n",
        "                    # Display results\n",
        "                    print(f\"\\nBased on your data:\")\n",
        "                    print(f\"- Height: {height}cm\")\n",
        "                    print(f\"- Weight: {weight}kg\")\n",
        "                    print(f\"- Age: {age}\")\n",
        "                    print(f\"- BMI: {weight / ((height/100)**2):.2f} ({bmi_cat})\")\n",
        "                    print(f\"- Age Category: {age_cat}\")\n",
        "                    print(f\"\\nWe recommend the following {num_workouts} workouts:\")\n",
        "\n",
        "                    for i, (workout, score) in enumerate(recommendations, 1):\n",
        "                        print(f\"{i}. {workout} (confidence: {score:.4f})\")\n",
        "\n",
        "                    another = input(\"\\nWant to try another recommendation? (y/n): \")\n",
        "                    if another.lower() != 'y':\n",
        "                        break\n",
        "\n",
        "                except ValueError:\n",
        "                    print(\"Error: Please enter valid numeric values.\")\n",
        "                    continue\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nExiting interactive mode.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the system\"\"\"\n",
        "    print(\"Workout Recommendation System\")\n",
        "    print(\"=============================\")\n",
        "\n",
        "    dataset_path = 'dataset1.csv'\n",
        "\n",
        "    print(f\"Using dataset: {dataset_path}\")\n",
        "\n",
        "    # Create and train the system\n",
        "    system = WorkoutRecommendationSystem()\n",
        "    metrics = system.train(dataset_path=dataset_path)\n",
        "\n",
        "    print(\"\\nFinal model metrics:\")\n",
        "    print(f\"- Loss: {metrics['test_loss']:.4f}\")\n",
        "    print(f\"- Hamming Loss: {metrics['test_hamming_loss']:.4f}\")\n",
        "    print(f\"- F1 Score: {metrics['test_f1']:.4f}\")\n",
        "    print(f\"- Binary Accuracy: {metrics['test_accuracy']:.4f}\")\n",
        "\n",
        "    # Run interactive mode\n",
        "    system.interactive_mode()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}